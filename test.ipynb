{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TESSDATA_PREFIX\"] = \"C:/Program Files/Tesseract-OCR/tessdata\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "IMAGE_SIZE = 1800\n",
    "BINARY_THREHOLD = 180\n",
    "\n",
    "def process_image_for_ocr(file_path):\n",
    "    # TODO : Implement using opencv\n",
    "    temp_filename = set_image_dpi(file_path)\n",
    "    im_new = remove_noise_and_smooth(temp_filename)\n",
    "    return im_new\n",
    "\n",
    "def set_image_dpi(file_path):\n",
    "    im = Image.open(file_path)\n",
    "    length_x, width_y = im.size\n",
    "    factor = max(1, int(IMAGE_SIZE / length_x))\n",
    "    size = factor * length_x, factor * width_y\n",
    "    # size = (1800, 1800)\n",
    "    im_resized = im.resize(size, Image.LANCZOS)\n",
    "    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.jpg')\n",
    "    temp_filename = temp_file.name\n",
    "    im_resized.save(temp_filename, dpi=(300, 300))\n",
    "    return temp_filename\n",
    "\n",
    "def image_smoothening(img):\n",
    "    ret1, th1 = cv2.threshold(img, BINARY_THREHOLD, 255, cv2.THRESH_BINARY)\n",
    "    ret2, th2 = cv2.threshold(th1, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    blur = cv2.GaussianBlur(th2, (1, 1), 0)\n",
    "    ret3, th3 = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    return th3\n",
    "\n",
    "def remove_noise_and_smooth(file_name):\n",
    "    img = cv2.imread(file_name, 0)\n",
    "    filtered = cv2.adaptiveThreshold(img.astype(np.uint8), 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 41,\n",
    "                                     3)\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    opening = cv2.morphologyEx(filtered, cv2.MORPH_OPEN, kernel)\n",
    "    closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel)\n",
    "    img = image_smoothening(img)\n",
    "    or_image = cv2.bitwise_or(img, closing)\n",
    "    return or_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('images/preprocessed_handwritten.jpg', process_image_for_ocr('images/handwritten.jpg'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OCR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'images/Template1_Instance0.jpg'\n",
    "# path = 'images/rvKPY.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ilyas\\anaconda3\\envs\\document-key-info-extraction\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "reader = easyocr.Reader(['en']) # this needs to run only once to load the model into memory\n",
    "result = reader.readtext(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = fitz.open(path)\n",
    "page = doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAX INVOICE\n",
      "Date: 20-Mar-2008\n",
      "Due Date\n",
      ": 16-Oct-2016\n",
      "PO Number :35\n",
      "Address:16424 Timothy Mission\n",
      "Bill to:Denise Perez\n",
      "Markville, AK 58294 US\n",
      "16424 Timothy Mission\n",
      "Markville, AK 58294 US\n",
      "Email:melvindO@example.net\n",
      "Tal:+(352)259-8443\n",
      "www.ThompsonandSons.org\n",
      "Email:melvind0@example.net\n",
      "(GSTIN: 12345670 00070007\n",
      "Site:http://smith_org/\n",
      "GSTIN: OG@AAMFCO376K124\n",
      "a\n",
      "7\n",
      "Pvc.\n",
      "CT\n",
      "Ste\n",
      "Total in words: seven hundred and thirt-\n",
      ";\n",
      "y-four point three three\n",
      "SUB_TOTAL : 725.30 EUR\n",
      "Bank Name\n",
      "State Bank of California\n",
      "DISCOUNT(1.85%): (-) 13.42\n",
      "Branch Name\n",
      "Raf CAMP\n",
      "TAX:VAT (3.88%): 28.18 EUR\n",
      "Bank Account Number 11695435\n",
      "Bank Swift Code\n",
      "SBININBB250\n",
      "TOTAL : 734.33 EUR\n",
      "Note:\n",
      "This order is shipped through blue dart courier\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make the TextPage object. It does all the OCR.\n",
    "full_tp = page.get_textpage_ocr(flags=0, dpi=300, full=True)\n",
    "\n",
    "# now look at what we have got\n",
    "print(page.get_text(textpage=full_tp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAX INVOICE\n",
      "Hels\n",
      "Es SR\n",
      "Due Date: 18-0ct2016\n",
      "Po Manor\n",
      "8\n",
      "Asdress:16424 Timothy Mission\n",
      "bil to:Dense Perez\n",
      "fare\n",
      "A S204 US\n",
      "$424 Toth scion\n",
      "Molle\n",
      "ar eeese US\n",
      "Email:melvin40@example.net\n",
      "Tel:+(352)259-8443\n",
      "cutee ooo\n",
      "eS\n",
      "bensikinn\n",
      "UST abasoT0 00070005\n",
      "Shorntpatomitergy\n",
      "GSTIN: OG@AAMFCO376K124\n",
      "a\n",
      "|\n",
      "a\n",
      "CT |\n",
      "2\n",
      "|\n",
      "|\n",
      "a\n",
      "TT |\n",
      "Teal\n",
      "esate ro anata\n",
      "Teel ocean\n",
      "suB_TOTAL: 72530 EUR\n",
      "ploy potttiree\n",
      "tee of Calforola\n",
      "DISCOUNTIL ASN) () 1342\n",
      "mates\n",
      "etcame\n",
      "Peruri ore\n",
      "Bani Aecour Number 11895435\n",
      "Bonk Suit Code\n",
      "SSMNNBDISO\n",
      "TOTAL: 73439 EUR\n",
      "note\n",
      "Ts oiesete ened evn bles aarrcoae\n",
      "\n"
     ]
    }
   ],
   "source": [
    "partial_tp = page.get_textpage_ocr(full=False, flags=0)\n",
    "\n",
    "# look at the result\n",
    "print(page.get_text(textpage=partial_tp))  # sort by vertical, then horizontal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'words': [], 'bboxes': []}\n",
    "\n",
    "for block in page.get_text(\"dict\", textpage=full_tp)[\"blocks\"]:\n",
    "    for line in block[\"lines\"]:\n",
    "        for span in line[\"spans\"]:\n",
    "            data['words'].append(span['text'])\n",
    "            bbox = list(map(int, span['bbox']))\n",
    "            data[\"bboxes\"].append(bbox)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LayoutLM for Question answering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This  order  is  shipped  through  blue  dart  courier\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, LayoutLMForQuestionAnswering\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"impira/layoutlm-document-qa\", add_prefix_space=True)\n",
    "model = LayoutLMForQuestionAnswering.from_pretrained(\"impira/layoutlm-document-qa\", revision=\"1e3ebac\")\n",
    "\n",
    "# dataset = load_dataset(\"nielsr/funsd\", split=\"train\")\n",
    "# example = dataset[0]\n",
    "question = \"What's the note?\"\n",
    "example = data\n",
    "words = example[\"words\"]\n",
    "boxes = example[\"bboxes\"]\n",
    "\n",
    "encoding = tokenizer(\n",
    "    question.split(), words, is_split_into_words=True, return_token_type_ids=True, return_tensors=\"pt\"\n",
    ")\n",
    "bbox = []\n",
    "for i, s, w in zip(encoding.input_ids[0], encoding.sequence_ids(0), encoding.word_ids(0)):\n",
    "    if s == 1:\n",
    "        bbox.append(boxes[w])\n",
    "    elif i == tokenizer.sep_token_id:\n",
    "        bbox.append([1000] * 4)\n",
    "    else:\n",
    "        bbox.append([0] * 4)\n",
    "encoding[\"bbox\"] = torch.tensor([bbox])\n",
    "\n",
    "word_ids = encoding.word_ids(0)\n",
    "outputs = model(**encoding)\n",
    "loss = outputs.loss\n",
    "start_scores = outputs.start_logits\n",
    "end_scores = outputs.end_logits\n",
    "start, end = word_ids[start_scores.argmax(-1)], word_ids[end_scores.argmax(-1)]\n",
    "print(\" \".join(words[start : end + 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LayoutLMv3 for question answering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image = Image.open(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LayoutLMv3ForQuestionAnswering were not initialized from the model checkpoint at microsoft/layoutlmv3-base and are newly initialized: ['qa_outputs.dense.bias', 'qa_outputs.dense.weight', 'qa_outputs.out_proj.bias', 'qa_outputs.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor, AutoModelForQuestionAnswering\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"microsoft/layoutlmv3-base\", apply_ocr=False)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"microsoft/layoutlmv3-base\")\n",
    "\n",
    "# dataset = load_dataset(\"nielsr/funsd-layoutlmv3\", split=\"train\")\n",
    "# example = dataset[0]\n",
    "# image = example[\"image\"]\n",
    "\n",
    "example = data\n",
    "question = \"what is the title\"\n",
    "words = example[\"words\"]\n",
    "boxes = example[\"bboxes\"]\n",
    "\n",
    "encoding = processor(image, question, words, boxes=boxes, return_tensors=\"pt\")\n",
    "start_positions = torch.tensor([1])\n",
    "end_positions = torch.tensor([3])\n",
    "\n",
    "\n",
    "outputs = model(**encoding, start_positions=start_positions, end_positions=end_positions)\n",
    "loss = outputs.loss\n",
    "start_scores = outputs.start_logits\n",
    "end_scores = outputs.end_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 13.42 Branch Name Raf CAMP TAX:VAT (3.88%): 28.18 EUR Bank Account Number 11695435 Bank Swift Code SBININBB250 TOTAL : 734.33 EUR Note: This order is shipped through blue dart courier\n"
     ]
    }
   ],
   "source": [
    "answer_start_index = outputs.start_logits.argmax()\n",
    "answer_end_index = outputs.end_logits.argmax()\n",
    "\n",
    "predict_answer_tokens = encoding.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "print(processor.decode(predict_answer_tokens, skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DOCUMENT-KEY-INFO-EXTRACTION",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
